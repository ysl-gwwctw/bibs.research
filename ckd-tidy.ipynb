{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score,mean_absolute_error, mean_squared_error\n",
    "#import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)  \n",
    "#n_split: Number of folds. Must be at least 2;n_repeates: Number of times cross-validator needs to be repeated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total datasets : (440, 68) (189, 68) (440,) (189,)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"ckd.analysis0706final.csv\")\n",
    "df=df.dropna(subset = [\"p8_p6.pctChangesPerYear\"])\n",
    "exclude=['Unnamed: 0','mdrd.GFR.x','rand_num','Phase','p8_p6','p8_p6.PerYear','p8_p6.pctChangesPerYear']\n",
    "feature_columns = list(df.columns.difference(exclude))\n",
    "TOTALx = df[feature_columns]\n",
    "TOTALy =  df['p8_p6.PerYear']\n",
    "\n",
    "TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty = train_test_split(TOTALx,TOTALy,train_size =0.7, test_size =0.3, random_state = 42)\n",
    "print(\"total datasets :\", TOTALtrainx.shape, TOTALtestx.shape, TOTALtrainy.shape, TOTALtesty.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "#trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "#trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "#trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.linear_model.LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1816    2.712149\n",
       "284     1.789362\n",
       "1667   -3.125030\n",
       "371     5.937312\n",
       "1331    0.691742\n",
       "          ...   \n",
       "232    -5.262595\n",
       "338     2.473916\n",
       "842     5.496735\n",
       "1378   -0.107303\n",
       "325     0.777197\n",
       "Name: p8_p6.pctChangesPerYear, Length: 440, dtype: float64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainy.head(440)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:552: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\", line 744, in fit\n",
      "    if self.alpha == 0:\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-4d10b40b1d9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgrid_search\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \"\"\"\n\u001b[0;32m    743\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m             warnings.warn(\"With alpha=0, this algorithm does not converge \"\n\u001b[0;32m    746\u001b[0m                           \u001b[1;34m\"well. You are advised to use the LinearRegression \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# define model evaluation method\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)  \n",
    "#n_split: Number of folds. Must be at least 2;n_repeates: Number of times cross-validator needs to be repeated.\n",
    "\n",
    "parameters = {'alpha': [np.arange(0,1,0.01)],\n",
    "             'max_iter':[100000,10000,1000]}\n",
    "\n",
    "grid_search = GridSearchCV(Lasso(),param_grid=parameters, cv=cv)        \n",
    "results = grid_search.fit(trainx, trainy)                          \n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "y_predict = best_model.predict(testx)\n",
    "print(\"Best model :\", best_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['alpha', 'copy_X', 'fit_intercept', 'max_iter', 'normalize', 'positive', 'precompute', 'random_state', 'selection', 'tol', 'warm_start'])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lasso().get_params().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "#trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "#trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "#trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "#import sklearn.svm as svm\n",
    "\n",
    "\n",
    "svm_reg = SVR(kernel = 'linear')\n",
    "\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 25, 50, 100],\n",
    "              'kernel':['rbf','linear'],\n",
    "             'gamma':[0.001, 0.01, 0.1, 1, 10, 25, 50, 100]}\n",
    "\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)  \n",
    "\n",
    "grid_svm = GridSearchCV(svm_reg,\n",
    "                      param_grid = parameters, cv = cv)\n",
    "\n",
    "grid_svm.fit(trainx, trainy)\n",
    "\n",
    "#result = pd.DataFrame(grid_svm.cv_results_['params'])\n",
    "#result['mean_test_score'] = grid_svm.cv_results_['mean_test_score']\n",
    "#result.sort_values(by='mean_test_score', ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_svm.best_estimator_\n",
    "#y_predict = best_model.predict(testx)\n",
    "\n",
    "y_predict = best_model.predict_proba(testx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=mean_squared_error(testy, y_predict)\n",
    "r2= r2_score(testy, y_predict)\n",
    "mae=mean_absolute_error(testy, y_predict)\n",
    "\n",
    "print(\"best model :\",best model)\n",
    "print(\"mse :\", mse)\n",
    "print(\"r2 :\",r2)\n",
    "print(\"mae :\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "#trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "#trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy\n",
    "\n",
    "svm_reg = SVR(kernel = 'linear')\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 25, 50, 100],\n",
    "              'kernel':['rbf','linear'],\n",
    "             'gamma':[0.001, 0.01, 0.1, 1, 10, 25, 50, 100]}\n",
    "\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)  \n",
    "\n",
    "grid_svm = GridSearchCV(svm_reg,\n",
    "                      param_grid = parameters, cv = cv)\n",
    "\n",
    "grid_svm.fit(trainx, trainy)\n",
    "y_predict = best_model.predict_proba(testx)\n",
    "\n",
    "mse=mean_squared_error(testy, y_predict)\n",
    "r2= r2_score(testy, y_predict)\n",
    "mae=mean_absolute_error(testy, y_predict)\n",
    "\n",
    "print(\"best model :\",best model)\n",
    "print(\"mse :\", mse)\n",
    "print(\"r2 :\",r2)\n",
    "print(\"mae :\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "#trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "#trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy\n",
    "\n",
    "svm_reg = SVR(kernel = 'linear')\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 25, 50, 100],\n",
    "              'kernel':['rbf','linear'],\n",
    "             'gamma':[0.001, 0.01, 0.1, 1, 10, 25, 50, 100]}\n",
    "\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)  \n",
    "\n",
    "grid_svm = GridSearchCV(svm_reg,\n",
    "                      param_grid = parameters, cv = cv)\n",
    "\n",
    "grid_svm.fit(trainx, trainy)\n",
    "y_predict = best_model.predict_proba(testx)\n",
    "\n",
    "mse=mean_squared_error(testy, y_predict)\n",
    "r2= r2_score(testy, y_predict)\n",
    "mae=mean_absolute_error(testy, y_predict)\n",
    "\n",
    "print(\"best model :\",best model)\n",
    "print(\"mse :\", mse)\n",
    "print(\"r2 :\",r2)\n",
    "print(\"mae :\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "#trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "#trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy\n",
    "\n",
    "svm_reg = SVR(kernel = 'linear')\n",
    "parameters = {'C': [0.001, 0.01, 0.1, 1, 10, 25, 50, 100],\n",
    "              'kernel':['rbf','linear'],\n",
    "             'gamma':[0.001, 0.01, 0.1, 1, 10, 25, 50, 100]}\n",
    "\n",
    "#cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)  \n",
    "\n",
    "grid_svm = GridSearchCV(svm_reg,\n",
    "                      param_grid = parameters, cv = cv)\n",
    "\n",
    "grid_svm.fit(trainx, trainy)\n",
    "y_predict = best_model.predict_proba(testx)\n",
    "\n",
    "mse=mean_squared_error(testy, y_predict)\n",
    "r2= r2_score(testy, y_predict)\n",
    "mae=mean_absolute_error(testy, y_predict)\n",
    "\n",
    "print(\"best model :\",best model)\n",
    "print(\"mse :\", mse)\n",
    "print(\"r2 :\",r2)\n",
    "print(\"mae :\", mae)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "#trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "#trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "#trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "parameters = {'n_estimators': [10,20,30,40,50,60,70,80,90,100],\n",
    "              'criterion':['mse'],\n",
    "              'max_depth':[2,3,4,5,6,7,8,9,10],\n",
    "              'max_features':['auto']} #default. auto: sqrt(전체 피처 개수)\n",
    "\n",
    "rf = RandomForestRegressor(oob_score=True, random_state=12)\n",
    "\n",
    "grid_RF = GridSearchCV(rf,param_grid = parameters, cv = cv)\n",
    "\n",
    "grid_RF.fit(trainx, trainy)\n",
    "best_model = grid_RF.best_estimator_\n",
    "y_predict = best_model.predict(testx)  ###### proba 지워야할지..\n",
    "\n",
    "mse=mean_squared_error(testy, y_predict)\n",
    "r2= r2_score(testy, y_predict)\n",
    "mae=mean_absolute_error(testy, y_predict)\n",
    "\n",
    "print(\"best model :\",best model)\n",
    "print(\"mse :\", mse)\n",
    "print(\"r2 :\",r2)\n",
    "print(\"mae :\", mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-5f78bc887c03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimportances_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimportances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mtop20\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimportances\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mascending\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfeature_importances_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    442\u001b[0m             \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mzeros\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m         \"\"\"\n\u001b[1;32m--> 444\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m         all_importances = Parallel(n_jobs=self.n_jobs,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "importances_values = rf.feature_importances_\n",
    "importances = pd.Series(importances_values, index=trainx.columns)\n",
    "top20 = importances.sort_values(ascending=False)\n",
    "#plt.figure(figsize=(8, 6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x = top20, y = top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "#trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "#trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy\n",
    "import seaborn as sns\n",
    "\n",
    "parameters = {'n_estimators': [10,20,30,40,50,60,70,80,90,100],\n",
    "              'criterion':['mse'],\n",
    "              'max_depth':[2,3,4,5,6,7,8,9,10],\n",
    "              'max_features':['auto']} #default. auto: sqrt(전체 피처 개수)\n",
    "\n",
    "rf = RandomForestRegressor(oob_score=True, random_state=12)\n",
    "\n",
    "grid_RF = GridSearchCV(rf,param_grid = parameters, cv = cv)\n",
    "\n",
    "grid_RF.fit(trainx, trainy)\n",
    "best_model = grid_RF.best_estimator_\n",
    "y_predict = best_model.predict(testx)  ###### proba 지워야할지..\n",
    "\n",
    "mse=mean_squared_error(testy, y_predict)\n",
    "r2= r2_score(testy, y_predict)\n",
    "mae=mean_absolute_error(testy, y_predict)\n",
    "\n",
    "print(\"best model :\",best model)\n",
    "print(\"mse :\", mse)\n",
    "print(\"r2 :\",r2)\n",
    "print(\"mae :\", mae)\n",
    "\n",
    "importances_values = rf.feature_importances_\n",
    "importances = pd.Series(importances_values, index=trainx.columns)\n",
    "top20 = importances.sort_values(ascending=False)\n",
    "#plt.figure(figsize=(8, 6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x = top20, y = top20.index)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "#trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "#trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy\n",
    "\n",
    "parameters = {'n_estimators': [10,20,30,40,50,60,70,80,90,100],\n",
    "              'criterion':['mse'],\n",
    "              'max_depth':[2,3,4,5,6,7,8,9,10],\n",
    "              'max_features':['auto']} #default. auto: sqrt(전체 피처 개수)\n",
    "\n",
    "rf = RandomForestRegressor(oob_score=True, random_state=12)\n",
    "\n",
    "grid_RF = GridSearchCV(rf,param_grid = parameters, cv = cv)\n",
    "\n",
    "grid_RF.fit(trainx, trainy)\n",
    "best_model = grid_RF.best_estimator_\n",
    "y_predict = best_model.predict(testx)  ###### proba 지워야할지..\n",
    "\n",
    "mse=mean_squared_error(testy, y_predict)\n",
    "r2= r2_score(testy, y_predict)\n",
    "mae=mean_absolute_error(testy, y_predict)\n",
    "\n",
    "print(\"best model :\",best model)\n",
    "print(\"mse :\", mse)\n",
    "print(\"r2 :\",r2)\n",
    "print(\"mae :\", mae)\n",
    "\n",
    "importances_values = rf.feature_importances_\n",
    "importances = pd.Series(importances_values, index=trainx.columns)\n",
    "top20 = importances.sort_values(ascending=False)\n",
    "#plt.figure(figsize=(8, 6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x = top20, y = top20.index)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainx, testx, trainy, testy = TOTALtrainx, TOTALtestx, TOTALtrainy, TOTALtesty\n",
    "#trainx, testx, trainy, testy = p6trainx, p6testx, p6trainy, p6testy\n",
    "#trainx, testx, trainy, testy = p7trainx, p7testx, p7trainy, p7testy\n",
    "trainx, testx, trainy, testy = p8trainx, p8testx, p8trainy, p8testy\n",
    "\n",
    "parameters = {'n_estimators': [10,20,30,40,50,60,70,80,90,100],\n",
    "              'criterion':['mse'],\n",
    "              'max_depth':[2,3,4,5,6,7,8,9,10],\n",
    "              'max_features':['auto']} #default. auto: sqrt(전체 피처 개수)\n",
    "\n",
    "rf = RandomForestRegressor(oob_score=True, random_state=12)\n",
    "\n",
    "grid_RF = GridSearchCV(rf,param_grid = parameters, cv = cv)\n",
    "\n",
    "grid_RF.fit(trainx, trainy)\n",
    "best_model = grid_RF.best_estimator_\n",
    "y_predict = best_model.predict(testx)  ###### proba 지워야할지..\n",
    "\n",
    "mse=mean_squared_error(testy, y_predict)\n",
    "r2= r2_score(testy, y_predict)\n",
    "mae=mean_absolute_error(testy, y_predict)\n",
    "\n",
    "print(\"best model :\",best model)\n",
    "print(\"mse :\", mse)\n",
    "print(\"r2 :\",r2)\n",
    "print(\"mae :\", mae)\n",
    "\n",
    "importances_values = rf.feature_importances_\n",
    "importances = pd.Series(importances_values, index=trainx.columns)\n",
    "top20 = importances.sort_values(ascending=False)\n",
    "#plt.figure(figsize=(8, 6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x = top20, y = top20.index)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
